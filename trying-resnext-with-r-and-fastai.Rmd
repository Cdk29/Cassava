---
title: "An R Markdown document converted from trying-resnext-with-r-and-fastai.ipynb from kaggle"
output: github_document
---

# Resnext with R

Resnexts and its derivative is one of the state of the art models for computer vision and ensemble well with efficientnet, so it is normal for me to try to train one. This kernal does not use keras. Two days ago I broke my tensorflow set up on my personnal computer. Apparently trying to uninstall and reinstall different version of keras to try to run the resnext can create unexpected mess that required the use of my emergency Ubuntu 20.10 pen drive to clean out.

**Spoiler alert :** it does not fully works and I hope this kernel will help debug some aspect of the wrapper.

Since I did not find convenient way to implement a resnext using keras, I will switch to fastai, which have implemented them since one year, even if I did not noticed at the time, despite [commenting the notebook](https://www.kaggle.com/jhoward/from-prototyping-to-submission-fastai). In this kernel I use a wrapper of fastai that enthousiast me quite a lot. Source material is https://henry090.github.io/fastai and https://www.kaggle.com/henry090/fast-ai-from-r-timm-learner.

If you have seen my other kernels it should not come as a surprise than I know fastai, since I reimplemented some kind of learning rate finder and cyclical learning rate finder in keras. What about the submissions ? Indeed, here we install a lot of things from internet. But a model trained here can be load in a python kernel, so there is no big problem about it, exept for using a Python kernel for the submission.

I found the wrapper quite tidious or frustrating to use sometimes, reproducing perfectly the original user's experience of fastai. So it is quite a good job in that regards.

```{r}
# This R environment comes with many helpful analytics packages installed
# It is defined by the kaggle/rstats Docker image: https://github.com/kaggle/docker-rstats
# For example, here's a helpful package to load

library(tidyverse) # metapackage of all tidyverse packages

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

list.files(path = "../input")

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session
```

```{r}
devtools::install_github("henry090/fastai",dependencies=FALSE)
#fastai::install_fastai(gpu = TRUE)
```

```{r}
#fastai::install_fastai(gpu = TRUE)
```

```{r}
library(fastai)
```

## Data loader

I am using this two ressources : [the documentation of fastai](https://docs.fast.ai/vision.data.html#ImageDataLoaders.from_df) and the [tutorial of the wrapper](https://henry090.github.io/fastai/articles/basic_img_class.html).

```{r}
path_img = 'cassava-leaf-disease-classification/train_images/'
```

```{r}
#library(data.table)
```

```{r}
labels<-read_csv('cassava-leaf-disease-classification//train.csv')
#labels = data.table::fread('/kaggle/input/cassava-leaf-disease-classification//train.csv')
head(labels)
```

```{r}
dataloader <- fastai::ImageDataLoaders_from_df(df=labels, path=path_img, bs=8, seed=6, device = 'cuda', num_workers=0, item_tfms = RandomResizedCrop(224, min_scale=0.75))
```

num_workers=0 is mandatory to not have the error "RuntimeError: DataLoader worker (pid(s) 482) exited unexpectedly".

```{r}
dataloader %>% show_batch()
```

If I had to bet, it is something related to kaggle/R environnement asking to define paremeters, as it works well in [the tutorial](https://henry090.github.io/fastai/articles/basic_img_class.html).

```{r}
learnR <- dataloader %>% cnn_learner(xresnet50(), metrics = accuracy,  model_dir="fastai_model/") #prettier
```

```{r}
#learnR %>% freeze()
#Error in freeze(.): could not find function "freeze"
```

```{r}
learnR$freeze()
```

Looking at the outputs of the kernel it does not seems to works (edit version 19 : actually it works).

```{r}
learnR %>% save(file="learnR")
```

```{r}
#learnR$export() 
#"[Errno 30] Read-only file system: '../input/cassava-leaf-disease-classification/train_images/export.pkl" aahhh it brings back memories.
```

At the moment xresnet50() create out of memory errors.

```{r}
learnR %>% lr_find()
```

```{r}
#learnR$recorder$lrs
#learnR$recorder$losses
```


```{r}
learnR %>% plot_lr_find(dpi = 200)
```

Thanks for the plot.

```{r}
#bss <- learnR %>% bs_find(lr=1e-3)

#learnR %>% plot_bs_find()
#Error in py_get_attr_impl(x, name, silent): AttributeError: 'Learner' object has no attribute 'bs_find'
```

```{r}
#learnR$bs_find <- learnR %>% bs_find(lr=1e-3)

#learnR %>% plot_bs_find()
#Error in py_get_attr_impl(x, name, silent): AttributeError: 'Learner' object has no attribute 'bs_find'
```

```{r}
#learnR$summary()
```

```{r}
learnR %>% fit_one_cycle(n_epoch = 10) #works
#printing of the output?
```

```{r interpretation}
interp <- ClassificationInterpretation_from_learner(learnR)

interp %>% plot_confusion_matrix(dpi =200,figsize = c(6,6))
```

Well, there is some bug around and funny behaviors. That being said, it is a wrapper, so it is normal to see weird things, and it is already a lot of works. It is normal that there is not thousands of tutorial to look after, you cannot think to everything before. And most of the problems came from fastai it self, such as the num_workers that you have to set to zero if you don't want the kernel to crash without comprehensive error message or the mystical manipulation of the working directory of the models I totally forgotten about before trying it today.

Also, I/we can just use the wrapper on our personnal computer, but I think it is not impossible to got all the outputs here on kaggle too.

